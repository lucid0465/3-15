{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JTxsWF-5sXG"
   },
   "source": [
    "\n",
    "# [KDT] ch7 Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering / PCA / Association Rule \n",
    "\n",
    " - 데이터셋: 직장인 연봉 정보 / 보스톤 집값 / 식료품 정보 데이터셋 \n",
    " - 주요 라이브러리: sklearn linear_model / sklearn.decomposition / mlxtend.preprocessing \n",
    " - 알파 퀴즈(1개) / 파이 퀴즈(1개) / 시그마 퀴즈(2개) / 오메가 퀴즈(과제 1개) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1668725561526,
     "user": {
      "displayName": "jinyang park",
      "userId": "06576046992691541404"
     },
     "user_tz": -540
    },
    "id": "Dtoe4P7Hwi_G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1668725562530,
     "user": {
      "displayName": "jinyang park",
      "userId": "06576046992691541404"
     },
     "user_tz": -540
    },
    "id": "2P_tOya1wwd_"
   },
   "outputs": [],
   "source": [
    "# 원본 파일 로딩 \n",
    "df_hk = pd.read_csv('.\\\\data\\\\hk_221206.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\alpha$(알파) 퀴즈:\n",
    "\n",
    "직장인 연봉 정보 데이터셋을 바탕으로 군집분석을 진행하고자 한다.\n",
    "<br> 군집분석 진행 전 워밍업으로 지표간 거리 구하기 문제를 풀어 보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>p(x1, y1), q(x2, y2) 일때 上) 맨허튼 거리, 下) 유클리드 거리 수식은 아래와 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$d\\left( p,q\\right)   = |x_{1}-x_{2}| + |y_{1}-y_{2}| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d\\left( p,q\\right)   = \\sqrt {  \\left( x_{1}-x_{2}\\right)^2 + \\left( y_{1}-y_{2}\\right)^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>jumin7</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>company</th>\n",
       "      <th>grades</th>\n",
       "      <th>salary</th>\n",
       "      <th>expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hkd1</td>\n",
       "      <td>990623-2</td>\n",
       "      <td>F</td>\n",
       "      <td>161.9</td>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>4100</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hkd10</td>\n",
       "      <td>900303-2</td>\n",
       "      <td>F</td>\n",
       "      <td>169.4</td>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>4720</td>\n",
       "      <td>2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hkd100</td>\n",
       "      <td>681205-2</td>\n",
       "      <td>F</td>\n",
       "      <td>168.3</td>\n",
       "      <td>55</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>7280</td>\n",
       "      <td>5905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hkd101</td>\n",
       "      <td>931226-2</td>\n",
       "      <td>F</td>\n",
       "      <td>155.3</td>\n",
       "      <td>28</td>\n",
       "      <td>AB</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>4060</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hkd102</td>\n",
       "      <td>920123-1</td>\n",
       "      <td>M</td>\n",
       "      <td>188.6</td>\n",
       "      <td>29</td>\n",
       "      <td>O</td>\n",
       "      <td>B</td>\n",
       "      <td>F</td>\n",
       "      <td>4390</td>\n",
       "      <td>4015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name    jumin7 gender  height  age blood_type company grades  salary  \\\n",
       "0    hkd1  990623-2      F   161.9   22          A       A      A    4100   \n",
       "1   hkd10  900303-2      F   169.4   31          A       A      B    4720   \n",
       "2  hkd100  681205-2      F   168.3   55          A       A      B    7280   \n",
       "3  hkd101  931226-2      F   155.3   28         AB       B      B    4060   \n",
       "4  hkd102  920123-1      M   188.6   29          O       B      F    4390   \n",
       "\n",
       "   expenditure  \n",
       "0         1975  \n",
       "1         2970  \n",
       "2         5905  \n",
       "3         2935  \n",
       "4         4015  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary         4100\n",
       "expenditure    1975\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#첫번째 데이터인 hkd1 의 정보값\n",
    "df_hk.iloc[0, 8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary         4720\n",
       "expenditure    2970\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#두번째 데이터인 hkd10 의 정보값\n",
    "df_hk.iloc[1, 8:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>quiz1)</b> 데이터셋의 첫번째 샘플과 두번째 샘플의 맨허튼거리를 구하라(변수는 salary, expenditure 2가지 활용) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs((df_hk.iloc[0, 8] - df_hk.iloc[1, 8])) + abs((df_hk.iloc[0, 9] - df_hk.iloc[1, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>quiz2)</b> 데이터셋의 첫번째 샘플과 두번째 샘플의 유클리드 거리를 구하라(변수는 salary, expenditure 2가지 활용) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1172.358733494147"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df_hk.iloc[0, 8] - df_hk.iloc[1, 8])**2 + (df_hk.iloc[0, 9] - df_hk.iloc[1, 9])**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-0 Clustering 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_hk 데이터 셋 250개 샘플을 활용하여 군집을 만들어 세그먼트 분석을 하고자 한다. \n",
    "<br> 먼저 계층형 군집분석을 진행한다.  \n",
    "<br> 군집분석시 활용할 변수는 <b>gender, age, company, grades, salary, expenditure</b> 이다.   \n",
    "<br> 이때 수치형 변수 age, salary, expenditure는 정규화를 진행하고 정규화한 칼럼은 각각 age_st, salary_st, expenditure_st로 명명한다\n",
    "<br> 명목형 변수 gender, company, grades는 더미변수화 한다.(drop_first 옵션 false, 순서는 표기된 대로 진행할 것) \n",
    "<br> 전체 데이터셋 순서는 표준화한 age, salary, expenditure와 나머지 gender, company, grades 더미변수다.  \n",
    "\n",
    "<br>\n",
    "<br> 위 전처리를 마친 후 데이터셋 이름은 <b>basetable1</b>로 명명한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df 생성\n",
    "df_hk_1= df_hk[['gender', \"age\", \"company\", \"grades\", \"salary\", \"expenditure\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaling ['age', 'salary', 'expenditure']\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "st = StandardScaler().fit( df_hk_1[['age', 'salary', 'expenditure']])\n",
    "st_table = pd.DataFrame(st.transform(df_hk_1[['age', 'salary', 'expenditure']]), columns=['age_st', 'salary_st', 'expenditure_st'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies ['gender', 'company', 'grades']\n",
    "df_dummy = pd.get_dummies( df_hk_1[['gender', 'company', 'grades']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>company</th>\n",
       "      <th>grades</th>\n",
       "      <th>salary</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>age_st</th>\n",
       "      <th>salary_st</th>\n",
       "      <th>expenditure_st</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>company_A</th>\n",
       "      <th>company_B</th>\n",
       "      <th>company_C</th>\n",
       "      <th>grades_A</th>\n",
       "      <th>grades_B</th>\n",
       "      <th>grades_C</th>\n",
       "      <th>grades_D</th>\n",
       "      <th>grades_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>4100</td>\n",
       "      <td>1975</td>\n",
       "      <td>-1.996162</td>\n",
       "      <td>-1.222845</td>\n",
       "      <td>-1.613278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>4720</td>\n",
       "      <td>2970</td>\n",
       "      <td>-0.954082</td>\n",
       "      <td>-0.887000</td>\n",
       "      <td>-1.077579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>7280</td>\n",
       "      <td>5905</td>\n",
       "      <td>1.824798</td>\n",
       "      <td>0.499716</td>\n",
       "      <td>0.502599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>4060</td>\n",
       "      <td>2935</td>\n",
       "      <td>-1.301442</td>\n",
       "      <td>-1.244513</td>\n",
       "      <td>-1.096422</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>B</td>\n",
       "      <td>F</td>\n",
       "      <td>4390</td>\n",
       "      <td>4015</td>\n",
       "      <td>-1.185655</td>\n",
       "      <td>-1.065756</td>\n",
       "      <td>-0.514960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>6990</td>\n",
       "      <td>4865</td>\n",
       "      <td>1.245864</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>-0.057328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>7110</td>\n",
       "      <td>4985</td>\n",
       "      <td>1.361651</td>\n",
       "      <td>0.407630</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>M</td>\n",
       "      <td>52</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>8000</td>\n",
       "      <td>6625</td>\n",
       "      <td>1.477438</td>\n",
       "      <td>0.889730</td>\n",
       "      <td>0.890240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>8760</td>\n",
       "      <td>7385</td>\n",
       "      <td>1.593224</td>\n",
       "      <td>1.301411</td>\n",
       "      <td>1.299417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>7470</td>\n",
       "      <td>6095</td>\n",
       "      <td>1.709011</td>\n",
       "      <td>0.602636</td>\n",
       "      <td>0.604893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender  age company grades  salary  expenditure    age_st  salary_st  \\\n",
       "0        F   22       A      A    4100         1975 -1.996162  -1.222845   \n",
       "1        F   31       A      B    4720         2970 -0.954082  -0.887000   \n",
       "2        F   55       A      B    7280         5905  1.824798   0.499716   \n",
       "3        F   28       B      B    4060         2935 -1.301442  -1.244513   \n",
       "4        M   29       B      F    4390         4015 -1.185655  -1.065756   \n",
       "..     ...  ...     ...    ...     ...          ...       ...        ...   \n",
       "245      F   50       A      A    6990         4865  1.245864   0.342627   \n",
       "246      F   51       A      A    7110         4985  1.361651   0.407630   \n",
       "247      M   52       A      B    8000         6625  1.477438   0.889730   \n",
       "248      M   53       A      B    8760         7385  1.593224   1.301411   \n",
       "249      F   54       A      B    7470         6095  1.709011   0.602636   \n",
       "\n",
       "     expenditure_st  gender_F  gender_M  company_A  company_B  company_C  \\\n",
       "0         -1.613278         1         0          1          0          0   \n",
       "1         -1.077579         1         0          1          0          0   \n",
       "2          0.502599         1         0          1          0          0   \n",
       "3         -1.096422         1         0          0          1          0   \n",
       "4         -0.514960         0         1          0          1          0   \n",
       "..              ...       ...       ...        ...        ...        ...   \n",
       "245       -0.057328         1         0          1          0          0   \n",
       "246        0.007279         1         0          1          0          0   \n",
       "247        0.890240         0         1          1          0          0   \n",
       "248        1.299417         0         1          1          0          0   \n",
       "249        0.604893         1         0          1          0          0   \n",
       "\n",
       "     grades_A  grades_B  grades_C  grades_D  grades_F  \n",
       "0           1         0         0         0         0  \n",
       "1           0         1         0         0         0  \n",
       "2           0         1         0         0         0  \n",
       "3           0         1         0         0         0  \n",
       "4           0         0         0         0         1  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "245         1         0         0         0         0  \n",
       "246         1         0         0         0         0  \n",
       "247         0         1         0         0         0  \n",
       "248         0         1         0         0         0  \n",
       "249         0         1         0         0         0  \n",
       "\n",
       "[250 rows x 19 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basetable1\n",
    "basetable1 = pd.concat( [df_hk_1, st_table, df_dummy], axis=1)\n",
    "basetable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>age_st</th>\n",
       "      <th>salary_st</th>\n",
       "      <th>expenditure_st</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>company_A</th>\n",
       "      <th>company_B</th>\n",
       "      <th>company_C</th>\n",
       "      <th>grades_A</th>\n",
       "      <th>grades_B</th>\n",
       "      <th>grades_C</th>\n",
       "      <th>grades_D</th>\n",
       "      <th>grades_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.00000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.240000</td>\n",
       "      <td>6357.480000</td>\n",
       "      <td>4971.480000</td>\n",
       "      <td>-6.039613e-16</td>\n",
       "      <td>1.119105e-16</td>\n",
       "      <td>4.081180e-16</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.653899</td>\n",
       "      <td>1849.791383</td>\n",
       "      <td>1861.112508</td>\n",
       "      <td>1.002006e+00</td>\n",
       "      <td>1.002006e+00</td>\n",
       "      <td>1.002006e+00</td>\n",
       "      <td>0.498286</td>\n",
       "      <td>0.498286</td>\n",
       "      <td>0.490881</td>\n",
       "      <td>0.490881</td>\n",
       "      <td>0.400802</td>\n",
       "      <td>0.465846</td>\n",
       "      <td>0.499703</td>\n",
       "      <td>0.33476</td>\n",
       "      <td>0.245244</td>\n",
       "      <td>0.165304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>1330.000000</td>\n",
       "      <td>-2.227735e+00</td>\n",
       "      <td>-1.775365e+00</td>\n",
       "      <td>-1.960540e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>5002.500000</td>\n",
       "      <td>3593.750000</td>\n",
       "      <td>-7.225088e-01</td>\n",
       "      <td>-7.339736e-01</td>\n",
       "      <td>-7.417573e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>6100.000000</td>\n",
       "      <td>4762.500000</td>\n",
       "      <td>-2.778880e-02</td>\n",
       "      <td>-1.394733e-01</td>\n",
       "      <td>-1.125129e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>7427.500000</td>\n",
       "      <td>6272.500000</td>\n",
       "      <td>7.827178e-01</td>\n",
       "      <td>5.796148e-01</td>\n",
       "      <td>7.004573e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>11990.000000</td>\n",
       "      <td>10865.000000</td>\n",
       "      <td>1.824798e+00</td>\n",
       "      <td>3.051057e+00</td>\n",
       "      <td>3.173017e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        salary   expenditure        age_st     salary_st  \\\n",
       "count  250.000000    250.000000    250.000000  2.500000e+02  2.500000e+02   \n",
       "mean    39.240000   6357.480000   4971.480000 -6.039613e-16  1.119105e-16   \n",
       "std      8.653899   1849.791383   1861.112508  1.002006e+00  1.002006e+00   \n",
       "min     20.000000   3080.000000   1330.000000 -2.227735e+00 -1.775365e+00   \n",
       "25%     33.000000   5002.500000   3593.750000 -7.225088e-01 -7.339736e-01   \n",
       "50%     39.000000   6100.000000   4762.500000 -2.778880e-02 -1.394733e-01   \n",
       "75%     46.000000   7427.500000   6272.500000  7.827178e-01  5.796148e-01   \n",
       "max     55.000000  11990.000000  10865.000000  1.824798e+00  3.051057e+00   \n",
       "\n",
       "       expenditure_st    gender_F    gender_M   company_A   company_B  \\\n",
       "count    2.500000e+02  250.000000  250.000000  250.000000  250.000000   \n",
       "mean     4.081180e-16    0.448000    0.552000    0.400000    0.400000   \n",
       "std      1.002006e+00    0.498286    0.498286    0.490881    0.490881   \n",
       "min     -1.960540e+00    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     -7.417573e-01    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     -1.125129e-01    0.000000    1.000000    0.000000    0.000000   \n",
       "75%      7.004573e-01    1.000000    1.000000    1.000000    1.000000   \n",
       "max      3.173017e+00    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        company_C    grades_A    grades_B   grades_C    grades_D    grades_F  \n",
       "count  250.000000  250.000000  250.000000  250.00000  250.000000  250.000000  \n",
       "mean     0.200000    0.316000    0.464000    0.12800    0.064000    0.028000  \n",
       "std      0.400802    0.465846    0.499703    0.33476    0.245244    0.165304  \n",
       "min      0.000000    0.000000    0.000000    0.00000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.00000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.00000    0.000000    0.000000  \n",
       "75%      0.000000    1.000000    1.000000    0.00000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.00000    1.000000    1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Clustering - Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age_st, salary_st, expenditure_st, gender, company, grades 각각 더미변수 총 13개 변수를 바탕으로 Hierarchical 군집분석을 시행한다\n",
    "<br>(sklearn AgglomerativeClustering 진행) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_st</th>\n",
       "      <th>salary_st</th>\n",
       "      <th>expenditure_st</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>company_A</th>\n",
       "      <th>company_B</th>\n",
       "      <th>company_C</th>\n",
       "      <th>grades_A</th>\n",
       "      <th>grades_B</th>\n",
       "      <th>grades_C</th>\n",
       "      <th>grades_D</th>\n",
       "      <th>grades_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996162</td>\n",
       "      <td>-1.222845</td>\n",
       "      <td>-1.613278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.954082</td>\n",
       "      <td>-0.887000</td>\n",
       "      <td>-1.077579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.824798</td>\n",
       "      <td>0.499716</td>\n",
       "      <td>0.502599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.301442</td>\n",
       "      <td>-1.244513</td>\n",
       "      <td>-1.096422</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.185655</td>\n",
       "      <td>-1.065756</td>\n",
       "      <td>-0.514960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1.245864</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>-0.057328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1.361651</td>\n",
       "      <td>0.407630</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.477438</td>\n",
       "      <td>0.889730</td>\n",
       "      <td>0.890240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1.593224</td>\n",
       "      <td>1.301411</td>\n",
       "      <td>1.299417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1.709011</td>\n",
       "      <td>0.602636</td>\n",
       "      <td>0.604893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_st  salary_st  expenditure_st  gender_F  gender_M  company_A  \\\n",
       "0   -1.996162  -1.222845       -1.613278         1         0          1   \n",
       "1   -0.954082  -0.887000       -1.077579         1         0          1   \n",
       "2    1.824798   0.499716        0.502599         1         0          1   \n",
       "3   -1.301442  -1.244513       -1.096422         1         0          0   \n",
       "4   -1.185655  -1.065756       -0.514960         0         1          0   \n",
       "..        ...        ...             ...       ...       ...        ...   \n",
       "245  1.245864   0.342627       -0.057328         1         0          1   \n",
       "246  1.361651   0.407630        0.007279         1         0          1   \n",
       "247  1.477438   0.889730        0.890240         0         1          1   \n",
       "248  1.593224   1.301411        1.299417         0         1          1   \n",
       "249  1.709011   0.602636        0.604893         1         0          1   \n",
       "\n",
       "     company_B  company_C  grades_A  grades_B  grades_C  grades_D  grades_F  \n",
       "0            0          0         1         0         0         0         0  \n",
       "1            0          0         0         1         0         0         0  \n",
       "2            0          0         0         1         0         0         0  \n",
       "3            1          0         0         1         0         0         0  \n",
       "4            1          0         0         0         0         0         1  \n",
       "..         ...        ...       ...       ...       ...       ...       ...  \n",
       "245          0          0         1         0         0         0         0  \n",
       "246          0          0         1         0         0         0         0  \n",
       "247          0          0         0         1         0         0         0  \n",
       "248          0          0         0         1         0         0         0  \n",
       "249          0          0         0         1         0         0         0  \n",
       "\n",
       "[250 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대상 df 생성, age_st, salary_st, expenditure_st, gender, company, grades 각각 더미변수 총 13개 변수\n",
    "basetable_cluster_1 = basetable1.iloc[ : , 6:]\n",
    "basetable_cluster_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgglomerativeClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster_1 = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward').fit(basetable_cluster_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(n_clusters=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attribute\n",
    "cluster_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2,\n",
       "       2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2,\n",
       "       1, 2, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2,\n",
       "       0, 0, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 1, 0, 0, 1, 2, 0, 0,\n",
       "       0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster_1.labels_\n",
    "cluster_1.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 계층형 군집분석 시각화: dendrogram(60개 샘플 대상)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dendrogram 그리기 (10개)\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "link_10 = linkage(basetable_cluster_1.iloc[:10, ], 'ward')\n",
    "dendrogram(link_10) \n",
    "plt.show()\n",
    "print(link_10) # link : cluster링 결과, 처음 두 개는 행 번호, 거리, 클러스터에 속한 데이터 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dendrogram 그리기 (60개)\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "plt.figure(figsize =(10,4))\n",
    "link_60 = linkage(basetable_cluster_1.iloc[:60, ], 'ward')\n",
    "dendrogram(link_60) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측, 새로운 정보값으로 예측할때 사용\n",
    "# basetable1['cluster_hier'] \n",
    "basetable1['cluster_hier'] = cluster_1.fit_predict( basetable_cluster_1) \n",
    "basetable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 타겟값 맵핑 {0:'a', 1:'b', 2:'c'}\n",
    "\n",
    "basetable1['cluster_hier'] = basetable1['cluster_hier'].map({0:'a', 1:'b', 2: 'c'})\n",
    "basetable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(basetable1['company'], basetable1['cluster_hier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster / company에 따른 scatter plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 회사별 분류 \n",
    "\n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=2, figsize=(14, 5))\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='company',  palette='Set1', ax= ax[0] )\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='cluster_hier',  palette='Set2', ax=ax[1] )\n",
    "\n",
    "ax[0].set_title('category : company ')\n",
    "ax[1].set_title('category : hierarchy cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hierarchy cluster는 군집 A: 고 연령 / 고 연봉 , 군집 B: 중상 연령, 중저 연봉, 군집 C: 저 연령 / 저 연봉 으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable1.groupby(['cluster_hier'])[['age', 'salary', 'expenditure']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable1.groupby(['cluster_hier'])[['age', 'salary', 'expenditure']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Clustering - K means\n",
    "\n",
    "age_st, salary_st, expenditure_st, gender, company, grades 각각 더미변수 총 13개 변수를 바탕으로 K-means 군집분석을 시행한다\n",
    "<br> (sklearn KMeans 진행, n_cluster = 3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basetable_cluster_1 (df, age_st, salary_st, expenditure_st, gender, company, grades 각각 더미변수 총 13개 변수)\n",
    "basetable_cluster_1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><kmeans split 에러시 threadpoolctl 업그레이드 필요> </b>\n",
    "<br>!pip install threadpoolctl --user --upgrade\n",
    "<br>import threadpoolctl\n",
    "<br>threadpoolctl.__version__ <- 3.0 이상 필요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means 모델 n_clusters=3, random_state=123\n",
    "# cluster_1_2 = \n",
    "cluster_1_2 = KMeans( n_clusters=3, random_state=123).fit(basetable_cluster_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Attribute 확인\n",
    "cluster_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k - means 라벨값 \n",
    "# basetable1['cluster_kmean'] = \n",
    "basetable1['cluster_kmean'] = cluster_1_2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# crosstab 'cluster_hier' 'cluster_kmean'\n",
    "pd.crosstab( basetable1['cluster_hier'], basetable1['cluster_kmean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# crosstab 'company' 'cluster_kmean'\n",
    "pd.crosstab( basetable1['company'], basetable1['cluster_kmean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사별 분류 \n",
    "\n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=3, figsize=(16, 5))\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='company',        palette='Set1', ax=ax[0] )\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='cluster_hier',   palette='Set1', ax=ax[1] )\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='cluster_kmean',  palette='Set1', ax=ax[2] )\n",
    "\n",
    "ax[0].set_title('category : company ')\n",
    "ax[1].set_title('category : hierarchy cluster')\n",
    "ax[2].set_title('category : kmeans cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. Clustering 평가 - Elbow score\n",
    "- kmeans inertia_ 활용\n",
    "\n",
    "Inertia 값, 군집화후 각 중심점에서 군집의 데이타간 거리를 합산한것으로 응집도를 나타내는 값 \n",
    "\n",
    "값이 작을 수록 응집도가 높게 군집화가 잘되었다고 평가할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_clusters=k를 1부터 10까지 적용\n",
    "\n",
    "inertias = []\n",
    "mapping = {}\n",
    "K = range(1, 10)\n",
    "\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(basetable_cluster_1) \n",
    "    inertias.append(kmeanModel.inertia_)\n",
    "    mapping[k] = kmeanModel.inertia_\n",
    "    print('k값 ', k , '=>', kmeanModel.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow score 시각화\n",
    "plt.plot(np.arange(1, 10), inertias, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method using Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-5. Clustering 평가 - Silhouette Test\n",
    "\n",
    "silhouette score는 1에 가까워야 positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_score = pd.DataFrame(columns =['k', 'score'])\n",
    "for i in np.arange(2, 7):\n",
    "    model_clustering = KMeans( n_clusters=i, random_state=123).fit(basetable_cluster_1)\n",
    "    a = silhouette_score( basetable_cluster_1,model_clustering.labels_)\n",
    "    k = pd.DataFrame({'k':[i], 'score':[a]})\n",
    "    k_score = pd.concat([k_score, k]).reset_index(drop=True)\n",
    "    print(\"K값 \", i, \" silhouette score: \", a.round(3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x='k', y='score', data=k_score)\n",
    "plt.xticks([2, 3, 4, 5, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K 값에 따른 scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K값 2~5까지 cluster_model, cluster_label 생성\n",
    "cluster_model_k1 = KMeans( n_clusters=2, random_state=123).fit(basetable_cluster_1)\n",
    "cluster_model_k2 = KMeans( n_clusters=3, random_state=123).fit(basetable_cluster_1)\n",
    "cluster_model_k3 = KMeans( n_clusters=4, random_state=123).fit(basetable_cluster_1)\n",
    "cluster_model_k4 = KMeans( n_clusters=5, random_state=123).fit(basetable_cluster_1)\n",
    "\n",
    "cluster_plot = basetable1.copy()\n",
    "cluster_plot['cluster_k1'] = cluster_model_k1.labels_\n",
    "cluster_plot['cluster_k2'] = cluster_model_k2.labels_\n",
    "cluster_plot['cluster_k3'] = cluster_model_k3.labels_\n",
    "cluster_plot['cluster_k4'] = cluster_model_k4.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K별 Plot \n",
    "\n",
    "fig, ax = plt.subplots( nrows= 2 , ncols=2, figsize=(8, 8))\n",
    "sns.scatterplot(x='age', y='salary', data=cluster_plot, hue='cluster_k1',  palette='Set1', ax= ax[0][0] )\n",
    "sns.scatterplot(x='age', y='salary', data=cluster_plot, hue='cluster_k2',  palette='Set1', ax=ax[0][1] )\n",
    "sns.scatterplot(x='age', y='salary', data=cluster_plot, hue='cluster_k3',  palette='Set1', ax=ax[1][0] )\n",
    "sns.scatterplot(x='age', y='salary', data=cluster_plot, hue='cluster_k4',  palette='Set1', ax=ax[1][1] )\n",
    "\n",
    "\n",
    "ax[0][0].set_title('K : 2')\n",
    "ax[0][1].set_title('K : 3')\n",
    "ax[1][0].set_title('K : 4')\n",
    "ax[1][1].set_title('K : 5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-6. Clustering 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "250개 데이터 셋을 바탕으로 군집분석을 실시 하였다.\n",
    "<br> 250개 외 추가 데이터 셋 샘플을 추가 할 경우, 모델을 바탕으로 기존 군집분석을 바탕으로 Cluster를 분류 할 수 있다. \n",
    "<br> 모델은 Kmeans 알고리즘을 통해 3개 cluster로 분류한 cluster_1_2 모델을 활용한다.\n",
    "\n",
    "<br> 데이터셋 샘플 - 성별:남성 / age:33 / company :C / grades: B / salary : 4500 / expenditure: 2975\n",
    "\n",
    "<br> <b>작업순서</b>\n",
    "<br> 1.수치형 변수 표준화 -> 2. 더미변수 확인 -> 3. 데이터 프레임에 맞춰 데이터 셋 준비 -> 4.Cluster 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basetable1\n",
    "basetable1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basetable_cluster_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_1 나이:33, 연봉:4500, 소비액:2975\n",
    "#sample_1 = \n",
    "sample_1 = pd.DataFrame({'age':[33], 'salary':[4500], 'expenditure':[2975]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기존 표준화 모델 활용\n",
    "st.transform(sample_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_1 DataFrame 변경\n",
    "#sample_1_num = \n",
    "sample_1_num = pd.DataFrame( st.transform(sample_1), columns = ['age_st', 'salary_st', 'expenditure_st'])\n",
    "sample_1_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy DataFrame 생성\n",
    "#sample_1_dummy =\n",
    "sample_1_dummy = pd.DataFrame( [[0,0,0,0,0,0,0,0,0,0]], columns = df_dummy.columns)\n",
    "sample_1_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy변수 정보값 생성, 'gender_M', 'company_C', 'grades_B'\n",
    "sample_1_dummy['gender_M'] = 1\n",
    "sample_1_dummy['company_C'] = 1\n",
    "sample_1_dummy['grades_B'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최종 DataFrame 만들기, sample_1_num,  sample_1_dummy concat\n",
    "# predic_sample1 = \n",
    "predic_sample1 = pd.concat([ sample_1_num, sample_1_dummy], axis=1)\n",
    "predic_sample1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predic_sample1로 cluster 예측\n",
    "cluster_1_2.predict( predic_sample1)\n",
    "# print(\"cluster 번호는 : \", cluster_1_2.predict( predic_sample1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz) 추가 예측 \n",
    "\n",
    "<br> cluster 예측모델로 아래 데이터의 결과를 예측하시오 \n",
    "<br> 성별:여성 / age:43 / company :B / grades: B / salary : 7900 / expenditure: 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 DataFrame을 사용하여 sample DataFrame 만들기 : to_dict() 활용\n",
    "basetable_cluster_1[:2]\n",
    "basetable_cluster_1[:1]\n",
    "basetable_cluster_1[:1].to_dict()\n",
    "\n",
    "#z표준화\n",
    "st.transform([[  43, 7900, 6000]]) \n",
    "\n",
    "# 추가 정보값 입력\n",
    "predic_sample2 = pd.DataFrame(\n",
    "{'age_st': {0: 0.43535785},\n",
    " 'salary_st': {0: 0.83556143},\n",
    " 'expenditure_st': {0: 0.5537458},\n",
    " 'gender_F': {0: 1},\n",
    " 'gender_M': {0: 0},\n",
    " 'company_A': {0: 0},\n",
    " 'company_B': {0: 1},\n",
    " 'company_C': {0: 0},\n",
    " 'grades_A': {0: 0},\n",
    " 'grades_B': {0: 1},\n",
    " 'grades_C': {0: 0},\n",
    " 'grades_D': {0: 0},\n",
    " 'grades_F': {0: 0}})\n",
    "\n",
    "predic_sample2\n",
    "\n",
    "\n",
    "cluster_1_2.predict( predic_sample2)\n",
    "print(\"cluster 번호는 : \", cluster_1_2.predict( predic_sample2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존방법\n",
    "sample_2 = pd.DataFrame({'age':[43], 'salary':[7900], 'expenditure':[6000]})\n",
    "sample_2_num = pd.DataFrame( st.transform(sample_2), columns = ['age_st', 'salary_st', 'expenditure_st'])\n",
    "sample_2_dummy = pd.DataFrame( [[0, 0,0,0,0,0,0,0,0,0]], columns = df_dummy.columns)\n",
    "sample_2_dummy['gender_F'][0] = 1\n",
    "sample_2_dummy['company_B'][0] = 1\n",
    "sample_2_dummy['grades_B'][0] = 1\n",
    "predic_sample2 = pd.concat([ sample_2_num, sample_2_dummy], axis=1)\n",
    "\n",
    "predic_sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predic_sample2로 cluster 예측\n",
    "print(\"cluster 번호는 : \",  cluster_1_2.predict( predic_sample2)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. $\\pi$(파이) 퀴즈 : 붓꽃 데이터 셋 활용 Kmeans / Hierachy \n",
    "\n",
    "sklearn 라이브러리 활용을 통한 붓꽃 품종 분류 \n",
    "<br>\n",
    "<br> 워밍업: x축을 'sepal_length'으로 y축을 'petal_length'로 scatter plot을 도식화 하시오. \n",
    "<br> 이때 라이브러리는 seaborn을 활용하고 'species' 그룹에 따라 색깔을 다르게 표현하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩 \n",
    "df_iris = pd.read_csv('.\\\\data\\\\iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris scatter plot, x='sepal_length',  y='petal_length'\n",
    "\n",
    "fig  = plt.figure( figsize=(5, 5))\n",
    "sns.scatterplot( data =df_iris, x='sepal_length',  y='petal_length', hue='species')\n",
    "\n",
    "plt.title('iris scatter plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> 계층형 군집분석을 통해 3개의 군집으로 분류하고자 한다. \n",
    "<br> 수치형 4개 변수 모두 활용해 minmax 정규화를 1차로 수행한 후 \n",
    "<br> sklearn의 AgglomerativeClustering 메소드를 활용, 하이퍼 파라미터값은 하단을 참조하여 군집분석을 수행하라\n",
    "<br> (n_clusters=3, affinity='manhattan', linkage='average')\n",
    "<br>\n",
    "<br><b> 문제: 3개 클러스터별 'sepal_length' 평균을 확인하고 평균값이 가장 높은 클러스터의 'sepal_length' 평균을 구하라</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_scaler = MinMaxScaler()\n",
    "iris_scaler.fit_transform(df_iris.drop('species', axis=1))\n",
    "df_iris_sc = pd.DataFrame( iris_scaler.fit_transform(df_iris.drop('species', axis=1)), columns = df_iris.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgglomerativeClustering, (n_clusters=3, affinity='manhattan', linkage='average')\n",
    "model_2 = AgglomerativeClustering(n_clusters=3, affinity='manhattan', linkage='average').fit(df_iris_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris['cluster'] = model_2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.groupby('cluster')['sepal_length'].mean().nlargest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab\n",
    "pd.crosstab(df_iris['species'], df_iris['cluster']) # setosa는 구분이 잘 됬고, versicolor, virginica 일부 중첩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "fig, ax = plt.subplots( nrows= 2 , ncols=2,  figsize=(10,10))\n",
    "\n",
    "sns.scatterplot( data = df_iris, x='sepal_length',  y='petal_length', hue='species' , palette='Set1', ax= ax[0][0])\n",
    "sns.scatterplot( data = df_iris,  x='sepal_length',  y='petal_length', hue='cluster', palette='Set2',ax= ax[0][1])\n",
    "sns.boxplot( data = df_iris, x='species', y='sepal_width' , palette='Set1', ax= ax[1][0])\n",
    "sns.boxplot( data = df_iris, x='cluster', y='sepal_width' , palette='Set2', ax= ax[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (추가) 집단간 sepal_length 평균 차이가 통계적으로 유의미하게 차이 나는지 확인해 보기 \n",
    "\n",
    "<br> species가 versicolor 인 데이터셋과 이와 유사한 클러스터와 sepal_length 평균 차이 확인해 본다.\n",
    "<br> shapiro 메소드를 통해 정규성을 확인하고 scipy의 ttest_ind 메소드를 활용할 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, ttest_ind\n",
    "\n",
    "# p-vaue 0.05 이상이면 정규성 만족 \n",
    "a = df_iris.loc[ df_iris['species']=='versicolor', 'sepal_length']\n",
    "b = df_iris.loc[ df_iris['cluster']==2, 'sepal_length']\n",
    "\n",
    "# shapiro Test, p-vaue 0.05 이상이면 정규성 만족 \n",
    "print( shapiro(a))\n",
    "print( shapiro(b)) \n",
    "\n",
    "# 두 집단의 평균의 차이, ttest_ind\n",
    "ttest_ind( a, b) # p_value 0.05 초과, 귀무가설 채택, 차이 없다 \n",
    "print( 'ttest_ind Result: ', ttest_ind( a, b))\n",
    "\n",
    "print( 'a.mean(): ', a.mean())\n",
    "print( 'b.mean(): ', b.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA \n",
    "\n",
    "<br> 주성분 분석(Principal Component Analysis, PCA) 가장 널리 사용되는 차원 축소 기법 중 하나\n",
    "<br> iris 데이터 활용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df 생성\n",
    "df_iris_2 = df_iris.iloc[ :, :4]\n",
    "df_iris_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='sepal_length', y='sepal_width', data=df_iris_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화\n",
    "iris_std = StandardScaler().fit_transform(df_iris_2)\n",
    "df_iris_std = pd.DataFrame(iris_std, columns =  df_iris_2.columns)\n",
    "df_iris_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#공분산행렬 확인 \n",
    "import numpy as np \n",
    "cov_matrix = np.cov(df_iris_std.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유값(분산설명력, explained_variance), 고유벡터 추출(사영계수, components)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#고유값(분산설명력, explained_variance)\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#고유벡터 추출(사영계수, components)\n",
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_iris = pd.DataFrame({'pca1':df_iris_std @ eigenvectors.T[0], 'pca2':df_iris_std @ eigenvectors.T[1], \n",
    "                         'pca3':df_iris_std @ eigenvectors.T[2], 'pca4':df_iris_std @ eigenvectors.T[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_iris[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 비교 \n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=2,  figsize=(6,3))\n",
    "\n",
    "sns.scatterplot(x = 'sepal_length', y = 'sepal_width', data=df_iris_2,   ax= ax[0])\n",
    "sns.scatterplot(x = 'pca1', y = 'pca2',                data=pca_iris,    ax= ax[1])\n",
    "\n",
    "ax[0].set_title('sepal_length, sepal_width')\n",
    "ax[1].set_title('pca1, pca2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA 라이브러리 \n",
    "from sklearn.decomposition import PCA\n",
    "pc = PCA()\n",
    "pc.fit(df_iris_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유값(분산설명력, explained_variance), eigenvalues 비교\n",
    "pc.explained_variance_, eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유벡터 확인(사영계수, components)\n",
    "pc.components_, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pca1\n",
    "df_iris_std @ pc.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvectors로 계산한것과 비교\n",
    "pca_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform으로 PCA 계산, df_iris_std @ pc.components_[0]\n",
    "pd.DataFrame(pc.transform(df_iris_std), columns=['PCA1', 'PCA2', 'PCA3', 'PCA4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 누적 분산 설명력(explained_variance_ratio_)\n",
    "print(pc.explained_variance_ratio_)\n",
    "print(pc.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누적 분산 설명력(explained_variance_ratio_) 시각화\n",
    "sns.lineplot(x = [1,2,3,4], y=pc.explained_variance_ratio_.cumsum())\n",
    "plt.xticks([1,2,3,4])\n",
    "plt.title('explained_variance_ratio_')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콘크리트 데이터 셋 활용, PCA 통해 만든 합성변수로 종속변수 strength을 예측하는 다중 회귀 분석 모델 설계\n",
    "<br>1030 rows × 9 columns\n",
    "<br> 라이브러리 : from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brick_concrete.csv 파일 로딩\n",
    "df_brick = pd.read_csv('.\\\\data\\\\yellowbrick_concrete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brick.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 변수별 상관계수 매트릭스 플롯 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "fig = plt.figure( figsize=(5,5))\n",
    "\n",
    "sns.heatmap( df_brick.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다중 공선성 VIF 로 feature 특성 파악\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['features'] = df_brick.columns\n",
    "vif['VIF'] = [variance_inflation_factor(df_brick.values, i) for i in range(df_brick.shape[1])]\n",
    "vif.sort_values('VIF', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF 지수가 10 초과하는 변수들이 다수 존재 \n",
    "<br> PCA를 통해 차원 축소, 복잡성을 줄이자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA 프로세스\n",
    "<br>1.정규화 -> 2. 공분산 행렬 계산 -> 3. 공분산 행렬 고유벡터와 고유값 계산 -> 4. 주성분 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "sc3 = StandardScaler()\n",
    "df_brick_sc = pd.DataFrame( sc3.fit_transform( df_brick.drop('strength', axis=1)), columns =  df_brick.drop('strength', axis=1).columns )\n",
    "df_brick_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 공분산 행렬 계산 / 3. 공분산 행렬 고유벡터와 고유값 계산\n",
    "sklearn.decomposition 라이브러리를 통해 자동 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(random_state=123).fit(df_brick_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유값  \n",
    "# pd.Series( pca_model.explained_variance_ )\n",
    "pca_model.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유벡터 (사영계수)\n",
    "pd.DataFrame(pca_model.components_, columns = df_brick_sc.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 주성분 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform, 이때 columns의 값은 pca1~8로 변경되어야 함\n",
    "pd.DataFrame( pca_model.transform(df_brick_sc) , columns = df_brick_sc.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성변수의 수는 행 수: 데이터셋 수 / 칼럼 수 : 데이터셋 칼럼 수\n",
    "데이터셋 칼럼 수 만큼의 합성 변수가 만들어 진다.\n",
    "<br>(ex: 10개의 칼럼이 있으면 PCA 후 합성변수 수는 총 10개) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#합성변수 transform + pca1~8 columns 생성 (1030 rows X 8 columns)\n",
    "df_brick_pca = pd.DataFrame( pca_model.transform(df_brick_sc) , columns = [ 'pca_'+ str(i) for i in  range(1,9)] )\n",
    "df_brick_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA 설명력 확인 6개 합성 변수를 통해 90% 이상 설명 가능 하다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 절차 정리\n",
    "1) df\n",
    "\n",
    "2) sc = StandardScaler().fit_transform(df)\n",
    "\n",
    "3) PCA().fit(sc) => explained_variance_ , explained_variance_ratio_\n",
    "\n",
    "4) PCA().fit_transform(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1) df (  df_brick_sc_1  )\n",
    "# 2) sc = StandardScaler().fit_transform(df)\n",
    "sc = StandardScaler().fit_transform( df_brick.drop('strength', axis=1))\n",
    "pd.DataFrame(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) PCA().fit(sc) => explained_variance_ , explained_variance_ratio_\n",
    "\n",
    "model_pca = PCA(random_state=123).fit(sc)\n",
    "model_pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4) PCA().fit_transform(sc)\n",
    "tran_pca = PCA(random_state=123).fit_transform(sc)\n",
    "pd.DataFrame(tran_pca)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. $\\pi$(파이) 퀴즈 : 아래 회귀분석을 시행하고 평가결과를 비교하시오\n",
    "\n",
    " - case 1) 종속변수: df_brick['strength'], 독립변수: df_brick_sc 변수 8개 로 회귀분석\n",
    " - case 2) 종속변수: df_brick['strength'], 독립변수: df_brick_sc PCA합성변수 6개 로 회귀분석\n",
    " - case 1)과 case 2)의 RMSE를 비교하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brick_sc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brick_pca[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Asociation rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "250명의 식료품 구매 이력을 바탕으로 연관성 분석 수행\n",
    "<br> (file: hkdataset_associaterules.csv - 식료품 데이터셋)\n",
    "<br> (file: hk_221206.csv - hk_table, 회사원 데이터 셋)\n",
    "\n",
    "<br> A회사 임직원을 대상으로 연관성 규칙 확인 \n",
    "<br> 우유를 단일 선행으로 하는 규칙을 만들며 후행 품목 수는 상관없다.    \n",
    "<br> 이를 위해 A회사 100명의 식료품 구매 이력을 확인하여 A회사 임직원 대상으로 장바구니 분석을 수행한다.\n",
    "<br> 이때 우유를 선행으로 하는 규칙 중 Lift 값이 가장 높은 item은 무엇인지 확인하시오.\n",
    "<br> HINT: 식료품 데이터셋과 회사원 데이터셋을 join하여 사용. \n",
    "<br> \n",
    "<br><b> 관련 라이브러리 및 하이퍼 파라미터 값 </b>\n",
    "<br> from mlxtend.preprocessing import TransactionEncoder\n",
    "<br> from mlxtend.frequent_patterns import apriori, association_rules\n",
    "<br> 조건 min_support=0.1, min_confidence=0.01\n",
    "\n",
    "Asociation rules 를 위해 mlxtend install 필요\n",
    "\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "df_asso = pd.read_csv('.\\\\data\\\\hkdataset_associaterules.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asso #250명의 식료품 구매 내역 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩 \n",
    "df_hk= pd.read_csv('.\\\\data\\\\hk_221206.csv')\n",
    "df_hk= df_hk.rename(columns = {'name':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge (left join)\n",
    "df_asso = pd.merge( df_asso, df_hk[['id', 'company']], how='left', on='id' )\n",
    "df_asso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asso['company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A회사 추출\n",
    "df_asso  = df_asso.loc[ df_asso['company'] == 'A', : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_asso[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case 1)\n",
    "# id별로 item 정리\n",
    "datatable3 = df_asso.groupby('id').apply( lambda x: x['item'].tolist()).reset_index().rename(columns={0:'item'})\n",
    "datatable3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import TransactionEncoder, apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "te1 = TransactionEncoder()\n",
    "te1_result = te1.fit(datatable3['item'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionEncoder attribute 확인\n",
    "te1.columns_mapping_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionEncoder attribute 확인\n",
    "te1.columns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "te1_trans = pd.DataFrame( te1.transform( datatable3['item']), columns =te1.columns_ )\n",
    "te1_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apriori\n",
    "apri1 = apriori(te1_trans, use_colnames=True,  min_support=0.1)\n",
    "apri1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# association_rules\n",
    "asso1 = association_rules( apri1, metric='confidence', min_threshold=0.5)  # 0.1\n",
    "asso1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asso1['antecedents'].values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우유를 사는 고객은 후행으로 어떤 상품을 많이 사는지 lift 내림차순으로 정렬 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "asso1.loc[ asso1['antecedents'] == frozenset({'Milk'}), : ].sort_values('lift', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : Corn(lift: 1.59) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case 2\n",
    "df_asso[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table 생성\n",
    "df_asso['cnt'] = True\n",
    "df_pivot = pd.pivot_table(df_asso, values='cnt', index='id', columns='item', aggfunc = 'max', fill_value= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apriori\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "apri2 = apriori(df_pivot, min_support= 0.1, use_colnames=True)\n",
    "apri2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# association_rules\n",
    "asso2 = association_rules( apri2, metric='confidence', min_threshold=0.5)  # 0.1\n",
    "asso2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$(오메가) Quiz1 (연관규칙을 생성하고 아래에 답하시오)\n",
    "\n",
    "Mart (association_rules_mart.csv) 데이터셋 활용 \n",
    "<br>40,000 rows X 3 columns\n",
    "\n",
    "<br>1. 한 번에 2개를 구매한 것은 삭제하시오. (ID와 Item이 중복되는것)\n",
    "<br>hint: drop_duplicates (34,766 rows)\n",
    "<br>2. 연관성 규칙을 생성하시오 (min_support=0.005, min_threshold=0.005)\n",
    "<br>3. 선행(antecedents)이 단일 Item 인것을 대상으로 데이터 셋을 구성하시오\n",
    "<br>4. support가 0.01보다 큰 것중(>= 0.01) lift가 가장 높은 선행, 후행 Item을 고르시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case1) pivot 사용\n",
    "# 파일 로딩\n",
    "df_mart = pd.read_csv('.\\\\data\\\\association_rules_mart.csv')\n",
    "df_mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) drop_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2) min_support=0.005, min_threshold=0.005\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apriori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3) antecedents이 단일 Item 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mart_asso_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step4) support가 0.01 보다 큰 것중 lift가 가장 높은 선행과 후행을 고르시오\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 2) transactionencoder 사용\n",
    "# 파일 로딩\n",
    "df_mart_2 = pd.read_csv('.\\\\data\\\\association_rules_mart.csv')\n",
    "df_mart_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) drop_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step2) min_support=0.005, min_threshold=0.005\n",
    "# step2) transactionencoding\n",
    "\n",
    "from mlxtend.preprocessing import transactionencoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apriori,  association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3) antecedents이 단일 Item 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mart_asso_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step4) support가 0.01 보다 큰 것중 lift가 가장 높은 선행과 후행을 고르시오\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$(오메가) Quiz2 (연관규칙을 생성하고 아래에 답하시오)\n",
    "\n",
    "seaborn 라이브러리 택시 데이터셋 활용 \n",
    "<br>6433 rows × 14 columns\n",
    "\n",
    "<br> 당신은 미국 맨하탄에 공유자동차 서비스를 기획하고자 한다. \n",
    "<br> 프로토타입으로 Upper East Side North에서 출발하는 가장 가능성이 높은 공유 노선을 설정하고자 한다. \n",
    "<br> 이를 위해 아래 단계를 거쳐 연관성 분석을 수행한다. \n",
    "<br> 1. 결측치 제거 후 진행 \n",
    "<br> 2. 택시 데이터 셋을 바탕으로 색상은 노랑색(yellow)에 맨허튼에서 픽업을 한 택시로 필터링한 데이터를 바탕으로 분석을 진행한다. \n",
    "<br> 3. pickup_zone/ dropoff_zone 칼럼을 이용하여 파생변수('rules')를 생성한다. ([pickup_zone, dropoff_zone] 형식)\n",
    "<br> ex) pickup_zone = 'A', dropoff_zone = 'B' 일때 [A, B]로 생성\n",
    "     hint) \n",
    "<br> 4. from mlxtend.preprocessing import TransactionEncoder를 바탕으로 연관성 분석 전처리 데이터셋을 만들고\n",
    "<br> 5. 연관성 분석을 실행하시오 (최소 기준 support =0.001, confidence = 0.1)\n",
    "<br>  5-1. lift가 가장 높은 선행, 후행 구간을 구하시오\n",
    "<br>  5-2. Bloomingdale가 선행일때 lift 값이 가장 높은 후행을 찾으시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1) TransactionEncoder 활용\n",
    "# step1 파일로딩, 결측치 제거,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2 yellow & Manhattan 필터링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3  pickup_zone, dropoff_zone 파생변수 ('rules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiz3['rules'] = [ [quiz3['pickup_zone'][i]] + [quiz3['dropoff_zone'][i]] for i in range(quiz3.shape[0]) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiz3[['pickup_zone','dropoff_zone']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4. TransactionEncoder로 연관성 분석 전처리 데이터셋 생성\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# te3.columns_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quiz3_te = pd.DataFrame( te_result3, columns= te3.columns_)\n",
    "quiz3_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step5) apriori, min_support=0.001\n",
    "quiz3_apr = apriori( quiz3_te, use_colnames=True, min_support=0.001)\n",
    "quiz3_apr.sort_values('support', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step 5-1) association_rules 도출, lift 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step 5-2) Bloomingdale가 선행일때 lift 값이 가장 높은 후행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case2) pivot_table 활용\n",
    "# step1 파일로딩, 결측치 제거,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2 yellow & Manhattan 필터링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3  pickup_zone, dropoff_zone 파생변수 ('rules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz3_1['pickup_zone'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quiz3_1['dropoff_zone'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiz3_1['rules'] = [ [quiz3_1['pickup_zone'][i]] + [quiz3_1['dropoff_zone'][i]] for i in range(quiz3_1.shape[0]) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# quiz3_1 = quiz3_1.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4. 연관성 분석 전처리 데이터셋 생성\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas.DataFrame.melt\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html?highlight=melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step5 apriori, min_support=0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step 5-1) association_rules 도출, lift 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step 5-2) Bloomingdale가 선행일때 lift 값이 가장 높은 후행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  $\\Sigma$ (시그마) Quiz ( 다이아몬드를 군집화하고 평균 가격을 분석하시오)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/shivam2503/diamonds\n",
    "\n",
    "데이터(diamonds.csv) 사이즈 : 53940 X 10\n",
    "<br> \n",
    "<br> <b>carat:</b> weight of the diamond (0.2--5.01)\n",
    "<br> <b>cut:</b> quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "<br> <b>color:</b> diamond colour, from D (best) to J (worst)\n",
    "<br> <b>clarity:</b> a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "<br> <b>depth:</b> total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "<br> <b>table:</b> width of top of diamond relative to widest point (43--95) \n",
    "<br> <b>price:</b> price in US dollars ($326--$18,823)\n",
    "<br> <b>x:</b> length in mm (0--10.74)\n",
    "<br> <b>y:</b> width in mm (0--58.9)\n",
    "<br> <b>z:</b> depth in mm (0--31.8)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz 1) diamond 데이터셋에 PCA를 적용하여 feature수를 줄이시오\n",
    "\n",
    "<br> 가장 값이 많이 나가는 다이아몬드 군집모형을 만들고자 한다. \n",
    "\n",
    "<br> 먼저 다이아몬드 데이터셋 중 carat은 0.7이상 0.8이하 데이터샘플만을 바탕으로한다. \n",
    "<br> 해당 데이터 셋의 모든 수치형 데이터를 활용하여 PCA를 진행한다(종속변수로 활용할 price는 제외)\n",
    "<br> 이때 분산설명력이 높은 순으로 확인할 시 누적 분산 설명력 90% 이상 확인할때 합성변수는 모두 몇개가 필요한가? \n",
    "\n",
    "<br> 이와 함께 위에서 확인한 변수 수를 바탕으로 PCA 합성변수로만 이루어진 데이터 셋을 만들고 데이터셋 명칭을 \n",
    "<br> quiz_table1 로 명명한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "quiz1 = pd.read_csv('.\\\\data\\\\diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# carat이 0.7이상~0.8이하 샘플만 확인\n",
    "\n",
    "\n",
    "\n",
    "# 수치형 변수 추출 과정\n",
    "\n",
    "\n",
    "\n",
    "# 수치형 변수 추출 \n",
    "\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# 수치형 변수 대상으로 PCA 진행(종속변수로 활용할 price는 제외)\n",
    "# 분산 설명력 90% 이상 해당하는 합성 변수\n",
    "\n",
    "# 분산설명력 확인, 90% 이상\n",
    "\n",
    "# quiz_table1 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz 2) diamond 데이터셋 - 계층형 군집 분석 후 모델 적합 \n",
    "\n",
    "<br>quiz_table1과 함께 이전 데이터셋에서의 모든 명목형 변수는 더미변수 처리(drop_first=True)하여 열결합을 수행한다.\n",
    "<br>이후 계층형 군집분석을 아래 옵션값을 확인하여 진행한다.\n",
    "<br>(메소드: AgglomerativeClustering, 클러스터 수 = 4, affinity='euclidean', linkage='ward')\n",
    "<br>클러스터별 다이아몬드 값 평균을 확인하고 평균값이 가장 높은 클러스터의 다이아몬드 평균값을 구하시오 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dummy 변수 생성\n",
    "\n",
    "# price, pca table, dummy table 결합\n",
    "\n",
    "# AgglomerativeClustering (n_clusters=4, affinity='euclidean', linkage='ward')\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "# 평균가격이 가장 높은 cluster은 ?\n",
    "\n",
    "# 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz 3) 클러스터별 평균 차이가 실제 유의미한 차이가 있는지 ANOVA 분석 및 pairwise_tukeyhsd 사후 분석 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f_oneway ANOVA 분석\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# pairwise_tukeyhsd 사후검정\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# 분석결과 확인\n",
    "\n",
    "# clarity: (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "# 유사한 carat 크기였지만 cluster=2 이 단가가 가장 높았음\n",
    "# clarity Sl1 / cut Ideal / color F 각 칼럼별 비중이 높았음\n",
    "\n",
    "# cut: (Fair, Good, Very Good, Premium, Ideal)\n",
    "\n",
    "# color: diamond colour, from D (best) to J (worst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDMucM2pMTNZILG4KX61Uv",
   "collapsed_sections": [
    "4JTxsWF-5sXG",
    "hfMi2HeL4piH",
    "5YwW9JcI1BcB",
    "0DC3DnJKED-q",
    "7OEylfG6Ou24",
    "z4IpIXV-edh3",
    "vhWiJegbvSiL",
    "rttRLvNIl51S",
    "X7ZNaAeiw8e1",
    "LrwKIIBM3AuA",
    "JpMOZEbbpdH6",
    "Ht5WvWhG6tun",
    "joz0fttoOWYJ"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
